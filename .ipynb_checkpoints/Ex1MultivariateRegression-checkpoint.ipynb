{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% Machine Learning Online Class\n",
    "%  Exercise 1: Linear regression with multiple variables\n",
    "%\n",
    "%  Instructions\n",
    "%  ------------\n",
    "% \n",
    "%  This file contains code that helps you get started on the\n",
    "%  linear regression exercise. \n",
    "%\n",
    "%  You will need to complete the following functions in this \n",
    "%  exericse:\n",
    "%\n",
    "%     warmUpExercise.m\n",
    "%     plotData.m\n",
    "%     gradientDescent.m\n",
    "%     computeCost.m\n",
    "%     gradientDescentMulti.m\n",
    "%     computeCostMulti.m\n",
    "%     featureNormalize.m\n",
    "%     normalEqn.mc\n",
    "%\n",
    "%  For this part of the exercise, you will need to change some\n",
    "%  parts of the code below for various experiments (e.g., changing\n",
    "%  learning rates).\n",
    "%\n",
    "\n",
    "%% Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### featureNormalize function, used in Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [X_norm, mu, sigma] = featureNormalize(X)\n",
    "%FEATURENORMALIZE Normalizes the features in X \n",
    "%   FEATURENORMALIZE(X) returns a normalized version of X where\n",
    "%   the mean value of each feature is 0 and the standard deviation\n",
    "%   is 1. This is often a good preprocessing step to do when\n",
    "%   working with learning algorithms.\n",
    "\n",
    "    % You need to set these values correctly\n",
    "    X_norm = X;\n",
    "    mu = zeros(1, size(X, 2));\n",
    "    sigma = zeros(1, size(X, 2));\n",
    "\n",
    "    % ====================== YOUR CODE HERE ======================\n",
    "    % Instructions: First, for each feature dimension, compute the mean\n",
    "    %               of the feature and subtract it from the dataset,\n",
    "    %               storing the mean value in mu. Next, compute the \n",
    "    %               standard deviation of each feature and divide\n",
    "    %               each feature by it's standard deviation, storing\n",
    "    %               the standard deviation in sigma. \n",
    "    %\n",
    "    %               Note that X is a matrix where each column is a \n",
    "    %               feature and each row is an example. You need \n",
    "    %               to perform the normalization separately for \n",
    "    %               each feature. \n",
    "    %\n",
    "    % Hint: You might find the 'mean' and 'std' functions useful.\n",
    "    %       \n",
    "\n",
    "    mu = mean(X);\n",
    "    sigma = std(X);\n",
    "    X_norm = (X - mu)./sigma;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### computeCostMulti, used in gradientDescentMulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "function J = computeCostMulti(X, y, theta)\n",
    "%COMPUTECOSTMULTI Compute cost for linear regression with multiple variables\n",
    "%   J = COMPUTECOSTMULTI(X, y, theta) computes the cost of using theta as the\n",
    "%   parameter for linear regression to fit the data points in X and y\n",
    "\n",
    "    % Initialize some useful values\n",
    "    m = length(y); % number of training examples\n",
    "\n",
    "    % You need to return the following variables correctly \n",
    "    J = 0;\n",
    "\n",
    "    % ====================== YOUR CODE HERE ======================\n",
    "    % Instructions: Compute the cost of a particular choice of theta\n",
    "    %               You should set J to the cost.\n",
    "\n",
    "    J = 1/(2 * m) * sum((X*theta - y).^2);\n",
    "\n",
    "\n",
    "\n",
    "    % =========================================================================\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradientDescentMulti, used in Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [theta, J_history] = gradientDescentMulti(X, y, theta, alpha, num_iters)\n",
    "%GRADIENTDESCENTMULTI Performs gradient descent to learn theta\n",
    "%   theta = GRADIENTDESCENTMULTI(x, y, theta, alpha, num_iters) updates theta by\n",
    "%   taking num_iters gradient steps with learning rate alpha\n",
    "\n",
    "    % Initialize some useful values\n",
    "    m = length(y); % number of training examples\n",
    "    J_history = zeros(num_iters, 1);\n",
    "\n",
    "    for iter = 1:num_iters\n",
    "\n",
    "        % ====================== YOUR CODE HERE ======================\n",
    "        % Instructions: Perform a single gradient step on the parameter vector\n",
    "        %               theta. \n",
    "        %\n",
    "        % Hint: While debugging, it can be useful to print out the values\n",
    "        %       of the cost function (computeCostMulti) and gradient here.\n",
    "        %\n",
    "\n",
    "\n",
    "    theta_temp = theta;\n",
    "    theta = theta_temp - alpha/m * (X'*(X*theta_temp - y));\n",
    "\n",
    "    % 3x1       3x1                 3x47 47x3 * 3x1  47x1      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        % ============================================================\n",
    "\n",
    "        % Save the cost J in every iteration    \n",
    "        J_history(iter) = computeCostMulti(X, y, theta);\n",
    "\n",
    "    end\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalEqn, used in part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [theta] = normalEqn(X, y)\n",
    "%NORMALEQN Computes the closed-form solution to linear regression \n",
    "%   NORMALEQN(X,y) computes the closed-form solution to linear \n",
    "%   regression using the normal equations.\n",
    "\n",
    "theta = zeros(size(X, 2), 1);\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Complete the code to compute the closed form solution\n",
    "%               to linear regression and put the result in theta.\n",
    "%\n",
    "\n",
    "% ---------------------- Sample Solution ----------------------\n",
    "\n",
    "theta = pinv(X' * X) * X' * y;\n",
    "\n",
    "#         3x97  97x3  3x97 97x1\n",
    "\n",
    "% -------------------------------------------------------------\n",
    "\n",
    "\n",
    "% ============================================================\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2J\n",
      "Loading data ...\n",
      "First 10 examples from the dataset: \n",
      " x = [2104 3], y = 399900 \n",
      " x = [1600 3], y = 329900 \n",
      " x = [2400 3], y = 369000 \n",
      " x = [1416 2], y = 232000 \n",
      " x = [3000 4], y = 539900 \n",
      " x = [1985 4], y = 299900 \n",
      " x = [1534 3], y = 314900 \n",
      " x = [1427 3], y = 198999 \n",
      " x = [1380 3], y = 212000 \n",
      " x = [1494 3], y = 242500 \n",
      "Normalizing Features ...\n",
      "mu is 2001 \n",
      "mu is 3 \n",
      "sigma is 795 \n",
      "sigma is 1 \n",
      "\u001b[H\u001b[2J\n"
     ]
    }
   ],
   "source": [
    "%% ================ Part 1: Feature Normalization ================\n",
    "\n",
    "%% Clear and Close Figures\n",
    "clear ; close all; clc\n",
    "\n",
    "fprintf('Loading data ...\\n');\n",
    "\n",
    "%% Load Data\n",
    "data = load('ex1data2.txt');\n",
    "X = data(:, 1:2);\n",
    "y = data(:, 3);\n",
    "m = length(y);\n",
    "\n",
    "% Print out some data points\n",
    "fprintf('First 10 examples from the dataset: \\n');\n",
    "fprintf(' x = [%.0f %.0f], y = %.0f \\n', [X(1:10,:) y(1:10,:)]');\n",
    "\n",
    "# fprintf('Program paused. Press enter to continue.\\n');\n",
    "# pause;\n",
    "\n",
    "% Scale features and set them to zero mean\n",
    "fprintf('Normalizing Features ...\\n');\n",
    "\n",
    "[X mu sigma] = featureNormalize(X);\n",
    "fprintf('mu is %.0f \\n', mu);\n",
    "fprintf('sigma is %.0f \\n', sigma);\n",
    "\n",
    "% Add intercept term to X\n",
    "X = [ones(m, 1) X];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gradient descent ...\n",
      "Set up the initial conditions \n"
     ]
    }
   ],
   "source": [
    "%% ================ Part 2: Gradient Descent ================\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: We have provided you with the following starter\n",
    "%               code that runs gradient descent with a particular\n",
    "%               learning rate (alpha). \n",
    "%\n",
    "%               Your task is to first make sure that your functions - \n",
    "%               computeCost and gradientDescent already work with \n",
    "%               this starter code and support multiple variables.\n",
    "%\n",
    "%               After that, try running gradient descent with \n",
    "%               different values of alpha and see which one gives\n",
    "%               you the best result.\n",
    "%\n",
    "%               Finally, you should complete the code at the end\n",
    "%               to predict the price of a 1650 sq-ft, 3 br house.\n",
    "%\n",
    "% Hint: By using the 'hold on' command, you can plot multiple\n",
    "%       graphs on the same figure.\n",
    "%\n",
    "% Hint: At prediction, make sure you do the same feature normalization.\n",
    "%\n",
    "\n",
    "fprintf('Running gradient descent ...\\n');\n",
    "\n",
    "% Choose some alpha value\n",
    "alpha = 0.10;\n",
    "num_iters = 400;\n",
    "fprintf('Set up the initial conditions \\n')\n",
    "\n",
    "% Init Theta and Run Gradient Descent \n",
    "theta = zeros(3, 1);\n",
    "[theta, J_history] = gradientDescentMulti(X, y, theta, alpha, num_iters);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta computed from gradient descent: \n",
      " 340412.659574 \n",
      " 110631.048958 \n",
      " -6649.472950 \n",
      "\n",
      "Final J = 2043280050.602829 \n",
      "Predicted price of a 1650 sq-ft, 3 br house (using gradient descent):\n",
      " $293081.464622\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"420px\" viewBox=\"0 0 560 420\" width=\"560px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "\n",
       "<title>Gnuplot</title>\n",
       "<desc>Produced by GNUPLOT 5.0 patchlevel 3 </desc>\n",
       "\n",
       "<g id=\"gnuplot_canvas\">\n",
       "\n",
       "<rect fill=\"none\" height=\"420\" width=\"560\" x=\"0\" y=\"0\"/>\n",
       "<defs>\n",
       "\n",
       "\t<circle id=\"gpDot\" r=\"0.5\" stroke-width=\"0.5\"/>\n",
       "\t<path d=\"M-1,0 h2 M0,-1 v2\" id=\"gpPt0\" stroke=\"currentColor\" stroke-width=\"0.333\"/>\n",
       "\t<path d=\"M-1,-1 L1,1 M1,-1 L-1,1\" id=\"gpPt1\" stroke=\"currentColor\" stroke-width=\"0.333\"/>\n",
       "\t<path d=\"M-1,0 L1,0 M0,-1 L0,1 M-1,-1 L1,1 M-1,1 L1,-1\" id=\"gpPt2\" stroke=\"currentColor\" stroke-width=\"0.333\"/>\n",
       "\t<rect height=\"2\" id=\"gpPt3\" stroke=\"currentColor\" stroke-width=\"0.333\" width=\"2\" x=\"-1\" y=\"-1\"/>\n",
       "\t<rect fill=\"currentColor\" height=\"2\" id=\"gpPt4\" stroke=\"currentColor\" stroke-width=\"0.333\" width=\"2\" x=\"-1\" y=\"-1\"/>\n",
       "\t<circle cx=\"0\" cy=\"0\" id=\"gpPt5\" r=\"1\" stroke=\"currentColor\" stroke-width=\"0.333\"/>\n",
       "\t<use fill=\"currentColor\" id=\"gpPt6\" stroke=\"none\" xlink:href=\"#gpPt5\"/>\n",
       "\t<path d=\"M0,-1.33 L-1.33,0.67 L1.33,0.67 z\" id=\"gpPt7\" stroke=\"currentColor\" stroke-width=\"0.333\"/>\n",
       "\t<use fill=\"currentColor\" id=\"gpPt8\" stroke=\"none\" xlink:href=\"#gpPt7\"/>\n",
       "\t<use id=\"gpPt9\" stroke=\"currentColor\" transform=\"rotate(180)\" xlink:href=\"#gpPt7\"/>\n",
       "\t<use fill=\"currentColor\" id=\"gpPt10\" stroke=\"none\" xlink:href=\"#gpPt9\"/>\n",
       "\t<use id=\"gpPt11\" stroke=\"currentColor\" transform=\"rotate(45)\" xlink:href=\"#gpPt3\"/>\n",
       "\t<use fill=\"currentColor\" id=\"gpPt12\" stroke=\"none\" xlink:href=\"#gpPt11\"/>\n",
       "\t<path d=\"M0,1.330 L1.265,0.411 L0.782,-1.067 L-0.782,-1.076 L-1.265,0.411 z\" id=\"gpPt13\" stroke=\"currentColor\" stroke-width=\"0.333\"/>\n",
       "\t<use fill=\"currentColor\" id=\"gpPt14\" stroke=\"none\" xlink:href=\"#gpPt13\"/>\n",
       "\t<filter filterUnits=\"objectBoundingBox\" height=\"1\" id=\"textbox\" width=\"1\" x=\"0\" y=\"0\">\n",
       "\t  <feFlood flood-color=\"white\" flood-opacity=\"1\" result=\"bgnd\"/>\n",
       "\t  <feComposite in=\"SourceGraphic\" in2=\"bgnd\" operator=\"atop\"/>\n",
       "\t</filter>\n",
       "\t<filter filterUnits=\"objectBoundingBox\" height=\"1\" id=\"greybox\" width=\"1\" x=\"0\" y=\"0\">\n",
       "\t  <feFlood flood-color=\"lightgrey\" flood-opacity=\"1\" result=\"grey\"/>\n",
       "\t  <feComposite in=\"SourceGraphic\" in2=\"grey\" operator=\"atop\"/>\n",
       "\t</filter>\n",
       "</defs>\n",
       "<g color=\"white\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"1.00\">\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"1.00\">\n",
       "\t<g shape-rendering=\"crispEdges\" stroke=\"none\">\n",
       "\t\t<polygon fill=\"rgb(255, 255, 255)\" points=\"54.0,381.6 543.0,381.6 543.0,11.4 54.0,11.4 \"/>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"rgb(255, 255, 255)\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M54.0,381.6 L62.4,381.6 M543.1,381.6 L534.7,381.6  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"end\" transform=\"translate(48.4,385.3)\">\n",
       "\t\t<text><tspan font-family=\"{}\">0</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M54.0,319.9 L62.4,319.9 M543.1,319.9 L534.7,319.9  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"end\" transform=\"translate(48.4,323.6)\">\n",
       "\t\t<text><tspan font-family=\"{}\">1e+10</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M54.0,258.2 L62.4,258.2 M543.1,258.2 L534.7,258.2  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"end\" transform=\"translate(48.4,261.9)\">\n",
       "\t\t<text><tspan font-family=\"{}\">2e+10</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M54.0,196.4 L62.4,196.4 M543.1,196.4 L534.7,196.4  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"end\" transform=\"translate(48.4,200.1)\">\n",
       "\t\t<text><tspan font-family=\"{}\">3e+10</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M54.0,134.7 L62.4,134.7 M543.1,134.7 L534.7,134.7  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"end\" transform=\"translate(48.4,138.4)\">\n",
       "\t\t<text><tspan font-family=\"{}\">4e+10</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M54.0,73.0 L62.4,73.0 M543.1,73.0 L534.7,73.0  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"end\" transform=\"translate(48.4,76.7)\">\n",
       "\t\t<text><tspan font-family=\"{}\">5e+10</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M54.0,11.3 L62.4,11.3 M543.1,11.3 L534.7,11.3  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"end\" transform=\"translate(48.4,15.0)\">\n",
       "\t\t<text><tspan font-family=\"{}\">6e+10</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M54.0,381.6 L54.0,373.2 M54.0,11.3 L54.0,19.7  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"middle\" transform=\"translate(54.0,397.3)\">\n",
       "\t\t<text><tspan font-family=\"{}\">0</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M115.1,381.6 L115.1,373.2 M115.1,11.3 L115.1,19.7  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"middle\" transform=\"translate(115.1,397.3)\">\n",
       "\t\t<text><tspan font-family=\"{}\">50</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M176.3,381.6 L176.3,373.2 M176.3,11.3 L176.3,19.7  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"middle\" transform=\"translate(176.3,397.3)\">\n",
       "\t\t<text><tspan font-family=\"{}\">100</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M237.4,381.6 L237.4,373.2 M237.4,11.3 L237.4,19.7  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"middle\" transform=\"translate(237.4,397.3)\">\n",
       "\t\t<text><tspan font-family=\"{}\">150</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M298.6,381.6 L298.6,373.2 M298.6,11.3 L298.6,19.7  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"middle\" transform=\"translate(298.6,397.3)\">\n",
       "\t\t<text><tspan font-family=\"{}\">200</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M359.7,381.6 L359.7,373.2 M359.7,11.3 L359.7,19.7  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"middle\" transform=\"translate(359.7,397.3)\">\n",
       "\t\t<text><tspan font-family=\"{}\">250</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M420.8,381.6 L420.8,373.2 M420.8,11.3 L420.8,19.7  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"middle\" transform=\"translate(420.8,397.3)\">\n",
       "\t\t<text><tspan font-family=\"{}\">300</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M482.0,381.6 L482.0,373.2 M482.0,11.3 L482.0,19.7  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"middle\" transform=\"translate(482.0,397.3)\">\n",
       "\t\t<text><tspan font-family=\"{}\">350</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M543.1,381.6 L543.1,373.2 M543.1,11.3 L543.1,19.7  \" stroke=\"black\"/>\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"middle\" transform=\"translate(543.1,397.3)\">\n",
       "\t\t<text><tspan font-family=\"{}\">400</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<path d=\"M54.0,11.3 L54.0,381.6 L543.1,381.6 L543.1,11.3 L54.0,11.3 Z  \" stroke=\"black\"/></g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"middle\" transform=\"translate(12.5,196.5) rotate(-90)\">\n",
       "\t\t<text><tspan font-family=\"{}\">Cost J</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "\t<g fill=\"rgb(0,0,0)\" font-family=\"{}\" font-size=\"10.00\" stroke=\"none\" text-anchor=\"middle\" transform=\"translate(298.5,415.3)\">\n",
       "\t\t<text><tspan font-family=\"{}\">Number of iterations</tspan></text>\n",
       "\t</g>\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "</g>\n",
       "\t<g id=\"gnuplot_plot_1a\"><title>gnuplot_plot_1a</title>\n",
       "<g color=\"white\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"2.00\">\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"2.00\">\n",
       "\t<path d=\"M55.2,52.7 L56.4,113.6 L57.7,162.5 L58.9,201.9 L60.1,233.6 L61.3,259.1 L62.6,279.7 L63.8,296.4   L65.0,309.9 L66.2,320.8 L67.5,329.6 L68.7,336.8 L69.9,342.6 L71.1,347.4 L72.3,351.2 L73.6,354.3   L74.8,356.9 L76.0,359.0 L77.2,360.7 L78.5,362.1 L79.7,363.2 L80.9,364.2 L82.1,365.0 L83.3,365.6   L84.6,366.1 L85.8,366.6 L87.0,366.9 L88.2,367.2 L89.5,367.5 L90.7,367.7 L91.9,367.9 L93.1,368.0   L94.4,368.1 L95.6,368.3 L96.8,368.3 L98.0,368.4 L99.2,368.5 L100.5,368.5 L101.7,368.6 L102.9,368.6   L104.1,368.7 L105.4,368.7 L106.6,368.7 L107.8,368.8 L109.0,368.8 L110.2,368.8 L111.5,368.8 L112.7,368.8   L113.9,368.9 L115.1,368.9 L116.4,368.9 L117.6,368.9 L118.8,368.9 L120.0,368.9 L121.3,368.9 L122.5,368.9   L123.7,368.9 L124.9,368.9 L126.1,368.9 L127.4,368.9 L128.6,368.9 L129.8,368.9 L131.0,369.0 L132.3,369.0   L133.5,369.0 L134.7,369.0 L135.9,369.0 L137.1,369.0 L138.4,369.0 L139.6,369.0 L140.8,369.0 L142.0,369.0   L143.3,369.0 L144.5,369.0 L145.7,369.0 L146.9,369.0 L148.2,369.0 L149.4,369.0 L150.6,369.0 L151.8,369.0   L153.0,369.0 L154.3,369.0 L155.5,369.0 L156.7,369.0 L157.9,369.0 L159.2,369.0 L160.4,369.0 L161.6,369.0   L162.8,369.0 L164.0,369.0 L165.3,369.0 L166.5,369.0 L167.7,369.0 L168.9,369.0 L170.2,369.0 L171.4,369.0   L172.6,369.0 L173.8,369.0 L175.1,369.0 L176.3,369.0 L177.5,369.0 L178.7,369.0 L179.9,369.0 L181.2,369.0   L182.4,369.0 L183.6,369.0 L184.8,369.0 L186.1,369.0 L187.3,369.0 L188.5,369.0 L189.7,369.0 L190.9,369.0   L192.2,369.0 L193.4,369.0 L194.6,369.0 L195.8,369.0 L197.1,369.0 L198.3,369.0 L199.5,369.0 L200.7,369.0   L202.0,369.0 L203.2,369.0 L204.4,369.0 L205.6,369.0 L206.8,369.0 L208.1,369.0 L209.3,369.0 L210.5,369.0   L211.7,369.0 L213.0,369.0 L214.2,369.0 L215.4,369.0 L216.6,369.0 L217.8,369.0 L219.1,369.0 L220.3,369.0   L221.5,369.0 L222.7,369.0 L224.0,369.0 L225.2,369.0 L226.4,369.0 L227.6,369.0 L228.9,369.0 L230.1,369.0   L231.3,369.0 L232.5,369.0 L233.7,369.0 L235.0,369.0 L236.2,369.0 L237.4,369.0 L238.6,369.0 L239.9,369.0   L241.1,369.0 L242.3,369.0 L243.5,369.0 L244.7,369.0 L246.0,369.0 L247.2,369.0 L248.4,369.0 L249.6,369.0   L250.9,369.0 L252.1,369.0 L253.3,369.0 L254.5,369.0 L255.8,369.0 L257.0,369.0 L258.2,369.0 L259.4,369.0   L260.6,369.0 L261.9,369.0 L263.1,369.0 L264.3,369.0 L265.5,369.0 L266.8,369.0 L268.0,369.0 L269.2,369.0   L270.4,369.0 L271.6,369.0 L272.9,369.0 L274.1,369.0 L275.3,369.0 L276.5,369.0 L277.8,369.0 L279.0,369.0   L280.2,369.0 L281.4,369.0 L282.7,369.0 L283.9,369.0 L285.1,369.0 L286.3,369.0 L287.5,369.0 L288.8,369.0   L290.0,369.0 L291.2,369.0 L292.4,369.0 L293.7,369.0 L294.9,369.0 L296.1,369.0 L297.3,369.0 L298.6,369.0   L299.8,369.0 L301.0,369.0 L302.2,369.0 L303.4,369.0 L304.7,369.0 L305.9,369.0 L307.1,369.0 L308.3,369.0   L309.6,369.0 L310.8,369.0 L312.0,369.0 L313.2,369.0 L314.4,369.0 L315.7,369.0 L316.9,369.0 L318.1,369.0   L319.3,369.0 L320.6,369.0 L321.8,369.0 L323.0,369.0 L324.2,369.0 L325.5,369.0 L326.7,369.0 L327.9,369.0   L329.1,369.0 L330.3,369.0 L331.6,369.0 L332.8,369.0 L334.0,369.0 L335.2,369.0 L336.5,369.0 L337.7,369.0   L338.9,369.0 L340.1,369.0 L341.3,369.0 L342.6,369.0 L343.8,369.0 L345.0,369.0 L346.2,369.0 L347.5,369.0   L348.7,369.0 L349.9,369.0 L351.1,369.0 L352.4,369.0 L353.6,369.0 L354.8,369.0 L356.0,369.0 L357.2,369.0   L358.5,369.0 L359.7,369.0 L360.9,369.0 L362.1,369.0 L363.4,369.0 L364.6,369.0 L365.8,369.0 L367.0,369.0   L368.2,369.0 L369.5,369.0 L370.7,369.0 L371.9,369.0 L373.1,369.0 L374.4,369.0 L375.6,369.0 L376.8,369.0   L378.0,369.0 L379.3,369.0 L380.5,369.0 L381.7,369.0 L382.9,369.0 L384.1,369.0 L385.4,369.0 L386.6,369.0   L387.8,369.0 L389.0,369.0 L390.3,369.0 L391.5,369.0 L392.7,369.0 L393.9,369.0 L395.1,369.0 L396.4,369.0   L397.6,369.0 L398.8,369.0 L400.0,369.0 L401.3,369.0 L402.5,369.0 L403.7,369.0 L404.9,369.0 L406.2,369.0   L407.4,369.0 L408.6,369.0 L409.8,369.0 L411.0,369.0 L412.3,369.0 L413.5,369.0 L414.7,369.0 L415.9,369.0   L417.2,369.0 L418.4,369.0 L419.6,369.0 L420.8,369.0 L422.0,369.0 L423.3,369.0 L424.5,369.0 L425.7,369.0   L426.9,369.0 L428.2,369.0 L429.4,369.0 L430.6,369.0 L431.8,369.0 L433.1,369.0 L434.3,369.0 L435.5,369.0   L436.7,369.0 L437.9,369.0 L439.2,369.0 L440.4,369.0 L441.6,369.0 L442.8,369.0 L444.1,369.0 L445.3,369.0   L446.5,369.0 L447.7,369.0 L448.9,369.0 L450.2,369.0 L451.4,369.0 L452.6,369.0 L453.8,369.0 L455.1,369.0   L456.3,369.0 L457.5,369.0 L458.7,369.0 L460.0,369.0 L461.2,369.0 L462.4,369.0 L463.6,369.0 L464.8,369.0   L466.1,369.0 L467.3,369.0 L468.5,369.0 L469.7,369.0 L471.0,369.0 L472.2,369.0 L473.4,369.0 L474.6,369.0   L475.8,369.0 L477.1,369.0 L478.3,369.0 L479.5,369.0 L480.7,369.0 L482.0,369.0 L483.2,369.0 L484.4,369.0   L485.6,369.0 L486.9,369.0 L488.1,369.0 L489.3,369.0 L490.5,369.0 L491.7,369.0 L493.0,369.0 L494.2,369.0   L495.4,369.0 L496.6,369.0 L497.9,369.0 L499.1,369.0 L500.3,369.0 L501.5,369.0 L502.7,369.0 L504.0,369.0   L505.2,369.0 L506.4,369.0 L507.6,369.0 L508.9,369.0 L510.1,369.0 L511.3,369.0 L512.5,369.0 L513.8,369.0   L515.0,369.0 L516.2,369.0 L517.4,369.0 L518.6,369.0 L519.9,369.0 L521.1,369.0 L522.3,369.0 L523.5,369.0   L524.8,369.0 L526.0,369.0 L527.2,369.0 L528.4,369.0 L529.6,369.0 L530.9,369.0 L532.1,369.0 L533.3,369.0   L534.5,369.0 L535.8,369.0 L537.0,369.0 L538.2,369.0 L539.4,369.0 L540.7,369.0 L541.9,369.0 L543.1,369.0    \" stroke=\"rgb(  0,   0, 255)\"/></g>\n",
       "\t</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"2.00\">\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"black\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "</g>\n",
       "<g color=\"black\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" stroke-width=\"0.50\">\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "% Plot the convergence graph\n",
    "# figure;\n",
    "plot(1:numel(J_history), J_history, '-b', 'LineWidth', 2);\n",
    "xlabel('Number of iterations');\n",
    "ylabel('Cost J');\n",
    "\n",
    "% Display gradient descent's result\n",
    "fprintf('Theta computed from gradient descent: \\n');\n",
    "fprintf(' %f \\n', theta);\n",
    "fprintf('\\n');\n",
    "fprintf('Final J = %f \\n', J_history(400));\n",
    "\n",
    "% Estimate the price of a 1650 sq-ft, 3 br house\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Recall that the first column of X is all-ones. Thus, it does\n",
    "% not need to be normalized.\n",
    "price = theta(1) + theta(2)*(1650-mu(1))/sigma(1) + theta(3)*(3-mu(2))/sigma(2); % You should change this\n",
    "\n",
    "\n",
    "% ============================================================\n",
    "\n",
    "fprintf(['Predicted price of a 1650 sq-ft, 3 br house ' ...\n",
    "         '(using gradient descent):\\n $%f\\n'], price);\n",
    "\n",
    "# fprintf('Program paused. Press enter to continue.\\n');\n",
    "# pause;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving with normal equations...\n",
      "Theta computed from the normal equations: \n",
      " 89597.909542 \n",
      " 139.210674 \n",
      " -8738.019112 \n",
      "\n",
      "Cost computed from the normal equations: \n",
      " 2043280050.602828 \n",
      "\n",
      "Predicted price of a 1650 sq-ft, 3 br house (using normal equations):\n",
      " $293081.464335\n"
     ]
    }
   ],
   "source": [
    "%% ================ Part 3: Normal Equations ================\n",
    "\n",
    "fprintf('Solving with normal equations...\\n');\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: The following code computes the closed form \n",
    "%               solution for linear regression using the normal\n",
    "%               equations. You should complete the code in \n",
    "%               normalEqn.m\n",
    "%\n",
    "%               After doing so, you should complete this code \n",
    "%               to predict the price of a 1650 sq-ft, 3 br house.\n",
    "%\n",
    "\n",
    "%% Load Data\n",
    "data = csvread('ex1data2.txt');\n",
    "X = data(:, 1:2);\n",
    "y = data(:, 3);\n",
    "m = length(y);\n",
    "\n",
    "% Add intercept term to X\n",
    "X = [ones(m, 1) X];\n",
    "\n",
    "% Calculate the parameters from the normal equation\n",
    "theta = normalEqn(X, y);\n",
    "\n",
    "% Display normal equation's result\n",
    "fprintf('Theta computed from the normal equations: \\n');\n",
    "fprintf(' %f \\n', theta);\n",
    "fprintf('\\n');\n",
    "\n",
    "# Calculate Cost with parameters calculated using the normal equation\n",
    "cost = computeCostMulti(X, y, theta);\n",
    "fprintf('Cost computed from the normal equations: \\n');\n",
    "fprintf(' %f \\n', cost);\n",
    "fprintf('\\n');\n",
    "\n",
    "\n",
    "# Estimate the price of a 1650 sq-ft, 3 br house\n",
    "H = [1; 1650; 3];\n",
    "price = theta' * H;\n",
    "\n",
    "\n",
    "% ============================================================\n",
    "\n",
    "fprintf(['Predicted price of a 1650 sq-ft, 3 br house ' ...\n",
    "         '(using normal equations):\\n $%f\\n'], price);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta$ is different when solving using the normal equations as the features are not normalized.  \n",
    "The predicted price is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
